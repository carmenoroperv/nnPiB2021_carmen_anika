N_FILTERS = ["25", "50", "75", "100"]

input_features_train = "data_preprocessed/genome/Seq_masked_wo_target_train.pt"
input_target_train = "data_preprocessed/genome/Target_C02M02_masked_arcsinh_train.pt"
input_features_val = "data_preprocessed/genome/Seq_masked_wo_target_val.pt"
input_target_val = "data_preprocessed/genome/Target_C02M02_masked_arcsinh_val.pt"

output = expand("tuning_results/conv_net_1_layer/TR1_n_filters/ConvNet_n_filters_{n_filter}/best_val_loss.txt", n_filter = N_FILTERS)

rule all: 
    input: output

rule conv_net_1_layer_manual_tune:
    input: 
        features_train = input_features_train,
        target_train = input_target_train,
        features_val = input_features_val,
        target_val = input_target_val
    output: 
        output = "tuning_results/conv_net_1_layer/TR1_n_filters/ConvNet_n_filters_{n_filter}/best_val_loss.txt"
    params:
        subfolder = "tuning_results/conv_net_1_layer/TR1_n_filters/ConvNet_n_filters_{n_filter}/",
        model_file_name = "nn_models.conv_net_1_layer",
        model_name = "ConvNet",
        batch_size = 1024,
        num_channels = "{n_filter}", 
        conv_kernel_size_nts = 25, 
        conv_kernel_stride = 4, 
        pool_kernel_size = 2, 
        learning_rate = 0.000001,
        weight_decay = 0.0001,
        h1_size = 300,
        max_epochs = 300,
        print_interval = 5,
        seed = 0, 
        resuming_training_model = "yes"
    threads: 8
    conda:
        "envs/nnPiB.yml"
    script: 
        "train_model_conv_net_1_layer.py"